{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GANv5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidijju/FastMRI/blob/master/GANv5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ksu_Fvu2vDTf",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VYFgyjtCvF19",
        "outputId": "4738fdeb-1bfd-42dd-9637-2ab390bd855d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1414
        }
      },
      "cell_type": "code",
      "source": [
        "#Import required libraries\n",
        "%autoreload 2\n",
        "!pip3 install --upgrade pip\n",
        "!pip3 install torch\n",
        "!pip3 install torchvision\n",
        "!pip3 install torchfusion\n",
        "!pip3 install tensorboardx\n",
        "!pip3 install pillow\n",
        "!pip3 install pydicom\n",
        "!pip3 install opencv-python\n",
        "\n",
        "import os\n",
        "import errno\n",
        "import scipy\n",
        "import pydicom as dicom\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "from tensorflow import nn, layers\n",
        "from tensorflow.contrib import layers as clayers \n",
        "\n",
        "import torch\n",
        "import torch.cuda as cuda\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.distributions import Normal\n",
        "\n",
        "import torchvision.utils as vutils\n",
        "from torchvision import transforms, utils, datasets\n",
        "\n",
        "from torchfusion.gan.learners import *\n",
        "from torchfusion.gan.applications import StandardGenerator,StandardProjectionDiscriminator\n",
        "from torchfusion.datasets import mnist_loader\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "from IPython import display\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from getpass import getpass\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/dc/7fd5df840efb3e56c8b4f768793a237ec4ee59891959d6a215d63f727023/pip-19.0.1-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.4MB 17.8MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 18.1\n",
            "    Uninstalling pip-18.1:\n",
            "      Successfully uninstalled pip-18.1\n",
            "Successfully installed pip-19.0.1\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 15.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.0)\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.4.1\n",
            "\u001b[0;31;1mWARNING: The following packages were previously imported in this runtime:\n",
            "  [PIL]\n",
            "You must restart the runtime in order to use newly installed versions.\u001b[0m\n",
            "Collecting torchfusion\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/10/eadb2b3223ef443aef3e5fc59d7aaa6d3d306bcfedf21d9ade95b41517fd/torchfusion-0.3.3-py3-none-any.whl (67kB)\n",
            "\u001b[K    100% |████████████████████████████████| 71kB 3.4MB/s \n",
            "\u001b[?25hCollecting visdom (from torchfusion)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/c4/5f5356fd57ae3c269e0e31601ea6487e0622fedc6756a591e4a5fd66cc7a/visdom-0.1.8.8.tar.gz (1.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.4MB 18.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from torchfusion) (3.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchfusion) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchfusion) (1.14.6)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (from torchfusion) (0.3.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from torchfusion) (0.2.1)\n",
            "Collecting tensorboardX (from torchfusion)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/76/89dd44458eb976347e5a6e75eb79fecf8facd46c1ce259bad54e0044ea35/tensorboardX-1.6-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 29.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from visdom->torchfusion) (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from visdom->torchfusion) (2.18.4)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from visdom->torchfusion) (4.5.3)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from visdom->torchfusion) (17.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from visdom->torchfusion) (1.11.0)\n",
            "Collecting torchfile (from visdom->torchfusion)\n",
            "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
            "Collecting websocket-client (from visdom->torchfusion)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/2d/f749a5c82f6192d77ed061a38e02001afcba55fe8477336d26a950ab17ce/websocket_client-0.54.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K    100% |████████████████████████████████| 204kB 26.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from visdom->torchfusion) (5.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torchfusion) (1.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torchfusion) (2.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torchfusion) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torchfusion) (2.5.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext->torchfusion) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->torchfusion) (3.6.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchfusion) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchfusion) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchfusion) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchfusion) (2018.11.29)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->torchfusion) (40.6.3)\n",
            "Building wheels for collected packages: visdom, torchfile\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ee/87/ce/a5023722374ca73b57fc8d4284ba6f973c01219b3c385a07e0\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n",
            "Successfully built visdom torchfile\n",
            "Installing collected packages: torchfile, websocket-client, visdom, tensorboardX, torchfusion\n",
            "Successfully installed tensorboardX-1.6 torchfile-0.1.0 torchfusion-0.3.3 visdom-0.1.8.8 websocket-client-0.54.0\n",
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.6/dist-packages (1.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardx) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardx) (1.14.6)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardx) (3.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardx) (40.6.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (5.4.1)\n",
            "Collecting pydicom\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/88/d3c419ab2e753e7651510882a53219373e78fb55294cb247dffd3934ea55/pydicom-1.2.2-py2.py3-none-any.whl (7.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 7.0MB 7.7MB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-1.2.2\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (3.4.5.20)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.14.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eyPmlwLJy6Ze",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "601bab39-9bd0-4af1-8d5e-3afd0af0062d"
      },
      "cell_type": "code",
      "source": [
        "class Logger:\n",
        "\n",
        "    def __init__(self, model_name, data_name):\n",
        "        self.model_name = model_name\n",
        "        self.data_name = data_name\n",
        "\n",
        "        self.comment = '{}_{}'.format(model_name, data_name)\n",
        "        self.data_subdir = '{}/{}'.format(model_name, data_name)\n",
        "\n",
        "        # TensorBoard\n",
        "        self.writer = SummaryWriter(comment=self.comment)\n",
        "\n",
        "    def log(self, d_error, g_error, epoch, n_batch, num_batches):\n",
        "\n",
        "        # var_class = torch.autograd.variable.Variable\n",
        "        if isinstance(d_error, torch.autograd.Variable):\n",
        "            d_error = d_error.data.cpu().numpy()\n",
        "        if isinstance(g_error, torch.autograd.Variable):\n",
        "            g_error = g_error.data.cpu().numpy()\n",
        "\n",
        "        step = Logger._step(epoch, n_batch, num_batches)\n",
        "        self.writer.add_scalar(\n",
        "            '{}/D_error'.format(self.comment), d_error, step)\n",
        "        self.writer.add_scalar(\n",
        "            '{}/G_error'.format(self.comment), g_error, step)\n",
        "\n",
        "    def log_images(self, images, num_images, epoch, n_batch, num_batches, format='NCHW', normalize=True):\n",
        "        '''\n",
        "        input images are expected in format (NCHW)\n",
        "        '''\n",
        "        if type(images) == np.ndarray:\n",
        "            images = torch.from_numpy(images)\n",
        "        \n",
        "        if format=='NHWC':\n",
        "            images = images.transpose(1,3)\n",
        "        \n",
        "\n",
        "        step = Logger._step(epoch, n_batch, num_batches)\n",
        "        img_name = '{}/images{}'.format(self.comment, '')\n",
        "\n",
        "        # Make horizontal grid from image tensor\n",
        "        horizontal_grid = vutils.make_grid(\n",
        "            images, normalize=normalize, scale_each=True)\n",
        "        # Make vertical grid from image tensor\n",
        "        nrows = int(np.sqrt(num_images))\n",
        "        grid = vutils.make_grid(\n",
        "            images, nrow=nrows, normalize=True, scale_each=True)\n",
        "\n",
        "        # Add horizontal images to tensorboard\n",
        "        self.writer.add_image(img_name, horizontal_grid, step)\n",
        "\n",
        "        # Save plots\n",
        "        self.save_torch_images(horizontal_grid, grid, epoch, n_batch)\n",
        "\n",
        "    def save_torch_images(self, horizontal_grid, grid, epoch, n_batch, plot_horizontal=True):\n",
        "        out_dir = './data/images/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "\n",
        "        # Plot and save horizontal\n",
        "        fig = plt.figure(figsize=(128, 128))\n",
        "        #plt.imshow(np.moveaxis(horizontal_grid.numpy(), 0, -1))\n",
        "        #plt.axis('off')\n",
        "        #if plot_horizontal:\n",
        "            #display.display(plt.gcf())\n",
        "        self._save_images(fig, epoch, n_batch, 'hori')\n",
        "        #plt.close()\n",
        "\n",
        "        # Save squared\n",
        "        fig = plt.figure()\n",
        "        #plt.imshow(np.moveaxis(grid.numpy(), 0, -1))\n",
        "        #plt.axis('off')\n",
        "        self._save_images(fig, epoch, n_batch)\n",
        "        #plt.close()\n",
        "\n",
        "    def _save_images(self, fig, epoch, n_batch, comment=''):\n",
        "        out_dir = './data/images/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "        fig.savefig('{}/{}_epoch_{}_batch_{}.png'.format(out_dir,\n",
        "                                                         comment, epoch, n_batch))\n",
        "\n",
        "    def display_status(self, epoch, num_epochs, n_batch, num_batches, d_error, g_error, d_pred_real, d_pred_fake):\n",
        "        \n",
        "        # var_class = torch.autograd.variable.Variable\n",
        "        if isinstance(d_error, torch.autograd.Variable):\n",
        "            d_error = d_error.data.cpu().numpy()\n",
        "        if isinstance(g_error, torch.autograd.Variable):\n",
        "            g_error = g_error.data.cpu().numpy()\n",
        "        if isinstance(d_pred_real, torch.autograd.Variable):\n",
        "            d_pred_real = d_pred_real.data\n",
        "        if isinstance(d_pred_fake, torch.autograd.Variable):\n",
        "            d_pred_fake = d_pred_fake.data\n",
        "        \n",
        "        \n",
        "        print('Epoch: [{}/{}], Batch Num: [{}/{}]'.format(\n",
        "            epoch,num_epochs, n_batch, num_batches)\n",
        "             )\n",
        "        print('Discriminator Loss: {:.4f}, Generator Loss: {:.4f}'.format(d_error, g_error))\n",
        "        print('D(x): {:.4f}, D(G(z)): {:.4f}'.format(d_pred_real.mean(), d_pred_fake.mean()))\n",
        "\n",
        "    def save_models(self, generator, discriminator, epoch):\n",
        "        out_dir = './data/models/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "        torch.save(generator.state_dict(),\n",
        "                   '{}/G_epoch_{}'.format(out_dir, epoch))\n",
        "        torch.save(discriminator.state_dict(),\n",
        "                   '{}/D_epoch_{}'.format(out_dir, epoch))\n",
        "\n",
        "    def close(self):\n",
        "        self.writer.close()\n",
        "\n",
        "    # Private Functionality\n",
        "\n",
        "    @staticmethod\n",
        "    def _step(epoch, n_batch, num_batches):\n",
        "        return epoch * num_batches + n_batch\n",
        "\n",
        "    @staticmethod\n",
        "    def _make_dir(directory):\n",
        "        try:\n",
        "            os.makedirs(directory)\n",
        "        except OSError as e:\n",
        "            if e.errno != errno.EEXIST:\n",
        "                raise\n",
        "                "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[autoreload of PIL.Image failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "ImportError: cannot import name 'py3'\n",
            "]\n",
            "[autoreload of PIL._binary failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "ImportError: cannot import name 'py3'\n",
            "]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "sA3b26-Ny8ki",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class OASISDataset(Dataset):\n",
        "          \n",
        "    def __init__(self, arr_name = \"T1_DCM\", transforms=None):\n",
        "        \n",
        "        self.transforms = transforms\n",
        "        self.FLAIR_DCM = []\n",
        "        self.ROI_DCM = []\n",
        "        self.T1_DCM = []\n",
        "        self.T2_DCM = []\n",
        "        self.data = torch.zeros(()).new_empty((22, 1, 512, 512))\n",
        "        \n",
        "        #get OASIS Data from private BitBucket (since the data is not available publicly)\n",
        "        \n",
        "        user = getpass('BitBucket user')\n",
        "        password = getpass('BitBucket password')\n",
        "        os.environ['BITBUCKET_AUTH'] = user + ':' + password.replace(\"@\", \"%40\")\n",
        "\n",
        "        !git clone https://$BITBUCKET_AUTH@bitbucket.org/sidijju/OASIS-Data.git\n",
        "        os.chdir(\"OASIS-Data/\")\n",
        "        \n",
        "        #Floydhub: \n",
        "        #root = \"/floyd/home/OASIS-Data/BRAINIX/DICOM/\"\n",
        "        \n",
        "        #Colaboratory:\n",
        "        root = \"/content/OASIS-Data/BRAINIX/DICOM/\"\n",
        "\n",
        "        #read in data\n",
        "        for dirName, subdirList, fileList in os.walk(\"/content/OASIS-Data/BRAINIX/DICOM/\"):\n",
        "            if(dirName == root + \"FLAIR\"):\n",
        "                for filename in fileList:\n",
        "                    self.FLAIR_DCM.append(os.path.join(dirName,filename))\n",
        "            if(dirName == root + \"ROI\"):\n",
        "                for filename in fileList:\n",
        "                    self.ROI_DCM.append(os.path.join(dirName,filename))\n",
        "            if(dirName == root + \"T1\"):\n",
        "                for filename in fileList:\n",
        "                    self.T1_DCM.append(os.path.join(dirName,filename))\n",
        "            if(dirName == root + \"T2\"):\n",
        "                for filename in fileList:\n",
        "                    self.T2_DCM.append(os.path.join(dirName,filename))\n",
        "\n",
        "        #self.FLAIR_Ref = self.getInfo(self.FLAIR_DCM)\n",
        "        #self.FLAIR_Dicom = np.zeros(self.FLAIR_Ref[1], dtype=self.FLAIR_Ref[0].pixel_array.dtype)\n",
        "        #self.storeList(self.FLAIR_DCM, self.FLAIR_Dicom)\n",
        "\n",
        "        #self.ROI_Ref = self.getInfo(self.ROI_DCM)\n",
        "        #self.ROI_Dicom = np.zeros(self.ROI_Ref[1], dtype=self.ROI_Ref[0].pixel_array.dtype)\n",
        "        #self.storeList(self.ROI_DCM, self.ROI_Dicom)\n",
        "        \n",
        "        #store T1 data\n",
        "        \n",
        "        self.T1_Ref = self.getInfo(self.T1_DCM)\n",
        "        self.T1_Dicom = np.zeros(self.T1_Ref[1], dtype=self.T1_Ref[0].pixel_array.dtype)\n",
        "        self.storeList(self.T1_DCM, self.T1_Dicom)\n",
        "\n",
        "        #self.T2_Ref = self.getInfo(self.T2_DCM)\n",
        "        #self.T2_Dicom = np.zeros(self.T2_Ref[1], dtype=self.T2_Ref[0].pixel_array.dtype)\n",
        "        #self.storeList(self.T2_DCM, self.T2_Dicom)\n",
        "        \n",
        "        if(arr_name == \"T1_DCM\"):\n",
        "            self.arr = self.T1_Dicom.reshape((22, 1, 512, 512))\n",
        "        elif(arr_name == \"T2_DCM\"):\n",
        "            self.arr = self.T2_Dicom\n",
        "        elif(arr_name == \"FLAIR_DCM\"):\n",
        "            self.arr = self.FLAIR_Dicom\n",
        "        else:\n",
        "            self.arr = self.ROI_Dicom \n",
        "        \n",
        "    def getInfo(self, ref):\n",
        "      \n",
        "          # Get ref file\n",
        "        RefDs = dicom.read_file(ref[0])\n",
        "\n",
        "          # Load dimensions based on the number of rows, columns, and slices (along the Z axis)\n",
        "        ConstPixelDims = (int(RefDs.Rows), int(RefDs.Columns), len(ref))\n",
        "          # Load spacing values (in mm)\n",
        "        ConstPixelSpacing = (float(RefDs.PixelSpacing[0]), float(RefDs.PixelSpacing[1]), float(RefDs.SliceThickness))\n",
        "          #calculate axes\n",
        "        x = np.arange(0.0, (ConstPixelDims[0]+1)*ConstPixelSpacing[0], ConstPixelSpacing[0])\n",
        "        y = np.arange(0.0, (ConstPixelDims[1]+1)*ConstPixelSpacing[1], ConstPixelSpacing[1])\n",
        "        z = np.arange(0.0, (ConstPixelDims[2]+1)*ConstPixelSpacing[2], ConstPixelSpacing[2])\n",
        "\n",
        "        return RefDs, ConstPixelDims, ConstPixelSpacing, x, y, z\n",
        "\n",
        "    def storeList(self, directory, array):\n",
        "        for filenameDCM in directory:\n",
        "            ds = dicom.read_file(filenameDCM)\n",
        "            array[:, :, int(filenameDCM[-6:-4]) - 1] = ds.pixel_array\n",
        "            \n",
        "    def plotPicture(self, im, ref, title=\"\"):\n",
        "        #plot picture of data\n",
        "        plt.figure(dpi=50)\n",
        "        plt.axes().set_aspect('equal', 'datalim')\n",
        "        plt.set_cmap(plt.gray())\n",
        "        plt.title(title)\n",
        "        plt.pcolormesh(self.T1_Ref[3], self.T1_Ref[4], im)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if index < np.size(self.arr,0) and index >= 0:\n",
        "            if self.transforms is not None:\n",
        "                self.plotPicture(self.arr[index].reshape((512, 512)), self.T1_Ref, \"Picture \" + str(index))\n",
        "                self.data.add(self.transforms(self.arr[index].astype('uint8')))\n",
        "            return self.arr[index].astype('uint8'), index\n",
        "        else:\n",
        "            print(\"INDEX INVALID\")\n",
        "            return None\n",
        "        \n",
        "    def __len__(self):\n",
        "        return np.size(self.arr,0)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HWfPrRoozB6m",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#load custom dataset with torch\n",
        "DATA_FOLDER = './tf_data/DCGAN/OASIS'\n",
        "def oasis_data():\n",
        "    compose = transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            #transforms.Normalize((.5, .5, .5), (.5, .5, .5)),\n",
        "        ])\n",
        "    out_dir = '{}/dataset'.format(DATA_FOLDER)\n",
        "    return OASISDataset(arr_name = \"T1_DCM\", transforms = compose)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "7pomCkMhvu5j"
      },
      "cell_type": "markdown",
      "source": [
        "##Define Standard Generator and Discriminator Models"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2Pr2kU41vuYY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b4abb8b6-efb5-418c-bfb4-cf97a9460fef"
      },
      "cell_type": "code",
      "source": [
        "print(\"Generator Initialization\")\n",
        "G = StandardGenerator(output_size=(128,128, 1),latent_size=128)\n",
        "print(\"Discriminator Initialization\")\n",
        "D = StandardProjectionDiscriminator(input_size=(128, 128, 1),apply_sigmoid=False)\n",
        "\n",
        "if cuda.is_available():\n",
        "    G = nn.DataParallel(G.cuda())\n",
        "    D = nn.DataParallel(D.cuda())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator Initialization\n",
            "Discriminator Initialization\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MAAyVIeMwud5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "g_optim = Adam(G.parameters(),lr=0.0002,betas=(0.5,0.999))\n",
        "d_optim = Adam(D.parameters(),lr=0.0002,betas=(0.5,0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8u45S0qhw6OT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learner = RAvgStandardGanLearner(G, D)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "voCnPsK0y1d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "abcfb70f-a5e5-492a-994a-b4bdf740f4ad"
      },
      "cell_type": "code",
      "source": [
        "dataset = oasis_data()\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BitBucket user··········\n",
            "BitBucket password··········\n",
            "Cloning into 'OASIS-Data'...\n",
            "remote: Counting objects: 119, done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 119 (delta 28), reused 119 (delta 28)\u001b[K\n",
            "Receiving objects: 100% (119/119), 189.42 MiB | 34.63 MiB/s, done.\n",
            "Resolving deltas: 100% (28/28), done.\n",
            "Checking out files: 100% (102/102), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pjNJzSoww6h6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6299002a-c0f9-4048-ff4c-7f1d843bcac4"
      },
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    learner.train(dataloader,gen_optimizer=g_optim,disc_optimizer=d_optim,save_outputs_interval=2,model_dir=\"./OASIS-gan\",latent_size=128,num_epochs=50,batch_log=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22\n",
            "Epoch 1 of 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0VhrUemfNg9D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}