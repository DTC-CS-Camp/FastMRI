{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GANv5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidijju/FastMRI/blob/master/GANv5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ksu_Fvu2vDTf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VYFgyjtCvF19",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "a33ac0cb-749d-48b3-e865-24084775b0d4"
      },
      "cell_type": "code",
      "source": [
        "#Import required libraries\n",
        "%autoreload 2\n",
        "!pip3 install --upgrade pip\n",
        "!pip3 install torch\n",
        "!pip3 install torchvision\n",
        "!pip3 install torchfusion\n",
        "!pip3 install tensorboardx\n",
        "!pip3 install pillow\n",
        "!pip3 install pydicom\n",
        "!pip3 install opencv-python\n",
        "\n",
        "import os\n",
        "import errno\n",
        "import scipy\n",
        "import pydicom as dicom\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "from tensorflow import nn, layers\n",
        "from tensorflow.contrib import layers as clayers \n",
        "\n",
        "import torch\n",
        "import torch.cuda as cuda\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.distributions import Normal\n",
        "\n",
        "import torchvision.utils as vutils\n",
        "from torchvision import transforms, utils, datasets\n",
        "\n",
        "from torchfusion.gan.learners import *\n",
        "from torchfusion.gan.applications import DCGANGenerator,DCGANDiscriminator\n",
        "from torchfusion.datasets import mnist_loader\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "from IPython import display\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from getpass import getpass\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (19.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: torchfusion in /usr/local/lib/python3.6/dist-packages (0.3.3)\n",
            "Requirement already satisfied: visdom in /usr/local/lib/python3.6/dist-packages (from torchfusion) (0.1.8.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from torchfusion) (3.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchfusion) (1.14.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchfusion) (4.28.1)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (from torchfusion) (1.6)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (from torchfusion) (0.3.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from torchfusion) (0.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from visdom->torchfusion) (1.1.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from visdom->torchfusion) (5.4.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from visdom->torchfusion) (17.0.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from visdom->torchfusion) (4.5.3)\n",
            "Requirement already satisfied: torchfile in /usr/local/lib/python3.6/dist-packages (from visdom->torchfusion) (0.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from visdom->torchfusion) (1.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from visdom->torchfusion) (2.18.4)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.6/dist-packages (from visdom->torchfusion) (0.54.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torchfusion) (1.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torchfusion) (2.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torchfusion) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torchfusion) (2.5.3)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->torchfusion) (3.6.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext->torchfusion) (1.0.0)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchfusion) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchfusion) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchfusion) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchfusion) (2018.11.29)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->torchfusion) (40.6.3)\n",
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.6/dist-packages (1.6)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardx) (3.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardx) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardx) (1.14.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardx) (40.6.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (5.4.1)\n",
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.6/dist-packages (1.2.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (3.4.5.20)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.14.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eyPmlwLJy6Ze",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Logger:\n",
        "\n",
        "    def __init__(self, model_name, data_name):\n",
        "        self.model_name = model_name\n",
        "        self.data_name = data_name\n",
        "\n",
        "        self.comment = '{}_{}'.format(model_name, data_name)\n",
        "        self.data_subdir = '{}/{}'.format(model_name, data_name)\n",
        "\n",
        "        # TensorBoard\n",
        "        self.writer = SummaryWriter(comment=self.comment)\n",
        "\n",
        "    def log(self, d_error, g_error, epoch, n_batch, num_batches):\n",
        "\n",
        "        # var_class = torch.autograd.variable.Variable\n",
        "        if isinstance(d_error, torch.autograd.Variable):\n",
        "            d_error = d_error.data.cpu().numpy()\n",
        "        if isinstance(g_error, torch.autograd.Variable):\n",
        "            g_error = g_error.data.cpu().numpy()\n",
        "\n",
        "        step = Logger._step(epoch, n_batch, num_batches)\n",
        "        self.writer.add_scalar(\n",
        "            '{}/D_error'.format(self.comment), d_error, step)\n",
        "        self.writer.add_scalar(\n",
        "            '{}/G_error'.format(self.comment), g_error, step)\n",
        "\n",
        "    def log_images(self, images, num_images, epoch, n_batch, num_batches, format='NCHW', normalize=True):\n",
        "        '''\n",
        "        input images are expected in format (NCHW)\n",
        "        '''\n",
        "        if type(images) == np.ndarray:\n",
        "            images = torch.from_numpy(images)\n",
        "        \n",
        "        if format=='NHWC':\n",
        "            images = images.transpose(1,3)\n",
        "        \n",
        "\n",
        "        step = Logger._step(epoch, n_batch, num_batches)\n",
        "        img_name = '{}/images{}'.format(self.comment, '')\n",
        "\n",
        "        # Make horizontal grid from image tensor\n",
        "        horizontal_grid = vutils.make_grid(\n",
        "            images, normalize=normalize, scale_each=True)\n",
        "        # Make vertical grid from image tensor\n",
        "        nrows = int(np.sqrt(num_images))\n",
        "        grid = vutils.make_grid(\n",
        "            images, nrow=nrows, normalize=True, scale_each=True)\n",
        "\n",
        "        # Add horizontal images to tensorboard\n",
        "        self.writer.add_image(img_name, horizontal_grid, step)\n",
        "\n",
        "        # Save plots\n",
        "        self.save_torch_images(horizontal_grid, grid, epoch, n_batch)\n",
        "\n",
        "    def save_torch_images(self, horizontal_grid, grid, epoch, n_batch, plot_horizontal=True):\n",
        "        out_dir = './data/images/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "\n",
        "        # Plot and save horizontal\n",
        "        fig = plt.figure(figsize=(128, 128))\n",
        "        #plt.imshow(np.moveaxis(horizontal_grid.numpy(), 0, -1))\n",
        "        #plt.axis('off')\n",
        "        #if plot_horizontal:\n",
        "            #display.display(plt.gcf())\n",
        "        self._save_images(fig, epoch, n_batch, 'hori')\n",
        "        #plt.close()\n",
        "\n",
        "        # Save squared\n",
        "        fig = plt.figure()\n",
        "        #plt.imshow(np.moveaxis(grid.numpy(), 0, -1))\n",
        "        #plt.axis('off')\n",
        "        self._save_images(fig, epoch, n_batch)\n",
        "        #plt.close()\n",
        "\n",
        "    def _save_images(self, fig, epoch, n_batch, comment=''):\n",
        "        out_dir = './data/images/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "        fig.savefig('{}/{}_epoch_{}_batch_{}.png'.format(out_dir,\n",
        "                                                         comment, epoch, n_batch))\n",
        "\n",
        "    def display_status(self, epoch, num_epochs, n_batch, num_batches, d_error, g_error, d_pred_real, d_pred_fake):\n",
        "        \n",
        "        # var_class = torch.autograd.variable.Variable\n",
        "        if isinstance(d_error, torch.autograd.Variable):\n",
        "            d_error = d_error.data.cpu().numpy()\n",
        "        if isinstance(g_error, torch.autograd.Variable):\n",
        "            g_error = g_error.data.cpu().numpy()\n",
        "        if isinstance(d_pred_real, torch.autograd.Variable):\n",
        "            d_pred_real = d_pred_real.data\n",
        "        if isinstance(d_pred_fake, torch.autograd.Variable):\n",
        "            d_pred_fake = d_pred_fake.data\n",
        "        \n",
        "        \n",
        "        print('Epoch: [{}/{}], Batch Num: [{}/{}]'.format(\n",
        "            epoch,num_epochs, n_batch, num_batches)\n",
        "             )\n",
        "        print('Discriminator Loss: {:.4f}, Generator Loss: {:.4f}'.format(d_error, g_error))\n",
        "        print('D(x): {:.4f}, D(G(z)): {:.4f}'.format(d_pred_real.mean(), d_pred_fake.mean()))\n",
        "\n",
        "    def save_models(self, generator, discriminator, epoch):\n",
        "        out_dir = './data/models/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "        torch.save(generator.state_dict(),\n",
        "                   '{}/G_epoch_{}'.format(out_dir, epoch))\n",
        "        torch.save(discriminator.state_dict(),\n",
        "                   '{}/D_epoch_{}'.format(out_dir, epoch))\n",
        "\n",
        "    def close(self):\n",
        "        self.writer.close()\n",
        "\n",
        "    # Private Functionality\n",
        "\n",
        "    @staticmethod\n",
        "    def _step(epoch, n_batch, num_batches):\n",
        "        return epoch * num_batches + n_batch\n",
        "\n",
        "    @staticmethod\n",
        "    def _make_dir(directory):\n",
        "        try:\n",
        "            os.makedirs(directory)\n",
        "        except OSError as e:\n",
        "            if e.errno != errno.EEXIST:\n",
        "                raise\n",
        "                "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sA3b26-Ny8ki",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class OASISDataset(Dataset):\n",
        "          \n",
        "    def __init__(self, arr_name = \"T1_DCM\", transforms=None):\n",
        "        \n",
        "        self.transforms = transforms\n",
        "        self.FLAIR_DCM = []\n",
        "        self.ROI_DCM = []\n",
        "        self.T1_DCM = []\n",
        "        self.T2_DCM = []\n",
        "        self.data = torch.zeros(()).new_empty((22, 512, 512))\n",
        "        \n",
        "        #get OASIS Data from private BitBucket (since the data is not available publicly)\n",
        "        \n",
        "        user = getpass('BitBucket user')\n",
        "        password = getpass('BitBucket password')\n",
        "        os.environ['BITBUCKET_AUTH'] = user + ':' + password.replace(\"@\", \"%40\")\n",
        "\n",
        "        !git clone https://$BITBUCKET_AUTH@bitbucket.org/sidijju/OASIS-Data.git\n",
        "        os.chdir(\"OASIS-Data/\")\n",
        "        \n",
        "        root = \"/content/OASIS-Data/BRAINIX/DICOM/\"\n",
        "\n",
        "        #read in data\n",
        "        for dirName, subdirList, fileList in os.walk(\"/content/OASIS-Data/BRAINIX/DICOM\"):\n",
        "            if(dirName == root + \"FLAIR\"):\n",
        "                for filename in fileList:\n",
        "                    self.FLAIR_DCM.append(os.path.join(dirName,filename))\n",
        "            if(dirName == root + \"ROI\"):\n",
        "                for filename in fileList:\n",
        "                    self.ROI_DCM.append(os.path.join(dirName,filename))\n",
        "            if(dirName == root + \"T1\"):\n",
        "                for filename in fileList:\n",
        "                    self.T1_DCM.append(os.path.join(dirName,filename))\n",
        "            if(dirName == root + \"T2\"):\n",
        "                for filename in fileList:\n",
        "                    self.T2_DCM.append(os.path.join(dirName,filename))\n",
        "\n",
        "        #self.FLAIR_Ref = self.getInfo(self.FLAIR_DCM)\n",
        "        #self.FLAIR_Dicom = np.zeros(self.FLAIR_Ref[1], dtype=self.FLAIR_Ref[0].pixel_array.dtype)\n",
        "        #self.storeList(self.FLAIR_DCM, self.FLAIR_Dicom)\n",
        "\n",
        "        #self.ROI_Ref = self.getInfo(self.ROI_DCM)\n",
        "        #self.ROI_Dicom = np.zeros(self.ROI_Ref[1], dtype=self.ROI_Ref[0].pixel_array.dtype)\n",
        "        #self.storeList(self.ROI_DCM, self.ROI_Dicom)\n",
        "        \n",
        "        #store T1 data\n",
        "        \n",
        "        self.T1_Ref = self.getInfo(self.T1_DCM)\n",
        "        self.T1_Dicom = np.zeros(self.T1_Ref[1], dtype=self.T1_Ref[0].pixel_array.dtype)\n",
        "        self.storeList(self.T1_DCM, self.T1_Dicom)\n",
        "\n",
        "        #self.T2_Ref = self.getInfo(self.T2_DCM)\n",
        "        #self.T2_Dicom = np.zeros(self.T2_Ref[1], dtype=self.T2_Ref[0].pixel_array.dtype)\n",
        "        #self.storeList(self.T2_DCM, self.T2_Dicom)\n",
        "        \n",
        "        if(arr_name == \"T1_DCM\"):\n",
        "            self.arr = self.T1_Dicom.reshape((512, 512, 1, 22))\n",
        "        elif(arr_name == \"T2_DCM\"):\n",
        "            self.arr = self.T2_Dicom\n",
        "        elif(arr_name == \"FLAIR_DCM\"):\n",
        "            self.arr = self.FLAIR_Dicom\n",
        "        else:\n",
        "            self.arr = self.ROI_Dicom \n",
        "        \n",
        "    def getInfo(self, ref):\n",
        "      \n",
        "          # Get ref file\n",
        "        RefDs = dicom.read_file(ref[0])\n",
        "\n",
        "          # Load dimensions based on the number of rows, columns, and slices (along the Z axis)\n",
        "        ConstPixelDims = (int(RefDs.Rows), int(RefDs.Columns), len(ref))\n",
        "          # Load spacing values (in mm)\n",
        "        ConstPixelSpacing = (float(RefDs.PixelSpacing[0]), float(RefDs.PixelSpacing[1]), float(RefDs.SliceThickness))\n",
        "          #calculate axes\n",
        "        x = np.arange(0.0, (ConstPixelDims[0]+1)*ConstPixelSpacing[0], ConstPixelSpacing[0])\n",
        "        y = np.arange(0.0, (ConstPixelDims[1]+1)*ConstPixelSpacing[1], ConstPixelSpacing[1])\n",
        "        z = np.arange(0.0, (ConstPixelDims[2]+1)*ConstPixelSpacing[2], ConstPixelSpacing[2])\n",
        "\n",
        "        return RefDs, ConstPixelDims, ConstPixelSpacing, x, y, z\n",
        "\n",
        "    def storeList(self, directory, array):\n",
        "        for filenameDCM in directory:\n",
        "            ds = dicom.read_file(filenameDCM)\n",
        "            array[:, :, int(filenameDCM[-6:-4]) - 1] = ds.pixel_array\n",
        "            \n",
        "    def plotPicture(self, im, ref, title=\"\"):\n",
        "        #plot picture of data\n",
        "        plt.figure(dpi=50)\n",
        "        plt.axes().set_aspect('equal', 'datalim')\n",
        "        plt.set_cmap(plt.gray())\n",
        "        plt.title(title)\n",
        "        plt.pcolormesh(self.T1_Ref[3], self.T1_Ref[4], im)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if index < np.size(self.arr,3) and index >= 0:\n",
        "            if self.transforms is not None:\n",
        "                self.plotPicture(self.arr[:, :, :, index].reshape((512, 512)), self.T1_Ref, \"Picture \" + str(index))\n",
        "                self.data.add(self.transforms(self.arr[:, :, :, index].astype('uint8')))\n",
        "            return self.arr[:, :, :, index].astype('uint8'), index\n",
        "        else:\n",
        "            print(\"INDEX INVALID\")\n",
        "            return None\n",
        "        \n",
        "    def __len__(self):\n",
        "        return np.size(self.arr,3)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HWfPrRoozB6m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#load custom dataset with torch\n",
        "DATA_FOLDER = './tf_data/DCGAN/OASIS'\n",
        "def oasis_data():\n",
        "    compose = transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            #transforms.Normalize((.5, .5, .5), (.5, .5, .5)),\n",
        "        ])\n",
        "    out_dir = '{}/dataset'.format(DATA_FOLDER)\n",
        "    return OASISDataset(arr_name = \"T1_DCM\", transforms = compose)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7pomCkMhvu5j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Define Standard Generator and Discriminator Models"
      ]
    },
    {
      "metadata": {
        "id": "2Pr2kU41vuYY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "G = DCGANGenerator(output_size=(1,512,512),latent_size=(128, 0))\n",
        "D = DCGANDiscriminator(input_size=(1,512,512),apply_sigmoid=False)\n",
        "\n",
        "if cuda.is_available():\n",
        "    G = nn.DataParallel(G.cuda())\n",
        "    D = nn.DataParallel(D.cuda())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MAAyVIeMwud5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "g_optim = Adam(G.parameters(),lr=0.0002,betas=(0.5,0.999))\n",
        "d_optim = Adam(D.parameters(),lr=0.0002,betas=(0.5,0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8u45S0qhw6OT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learner = RAvgStandardGanLearner(G, D)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "voCnPsK0y1d9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = oasis_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pjNJzSoww6h6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    learner.train(dataset,gen_optimizer=g_optim,disc_optimizer=d_optim,save_outputs_interval=500,model_dir=\"./OASIS-gan\",latent_size=128,num_epochs=50,batch_log=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}